---
layout: default 
---
<p style='text-align: justify;'><b>Our workshop aims to develop secure, privacy-preserving and fairness-aware techniques that span both optimization and learning domains.</b></p>

# <span style="display:block;text-align:center">Topic and Content</span>

<p style='text-align: justify;'>
Optimization and machine learning problems are pervasive in economic, scientific, and engineering applications. While significant advancements have been made in both fields, traditional 
approaches often assume that all resources and data for a task are centralized on a single device. Unfortunately, the assumption is violated in many applications with the growing storage of personal data and computational power of edge devices. Over the past years, federated learning (FL) has become a popular machine learning paradigm that can leverage distributed data without leaking sensitive information. Similarly, federated optimization techniques are being developed to solve complex optimization problems using distributed data and computational resources. Both approaches aim to leverage collective intelligence while preserving individual privacy. Furthermore, jointly addressing optimization and learning tasks among multiple edge devices with distributed data raises concerns about data security, privacy protection and fairness. In both federated learning and data-driven optimization, outcomes can be affected by data or algorithmic biases, potentially generating unfair results. When the outcomes of these federated processes correlate with real-world rewards (e.g., financial gains or resource allocation), participants may be hesitant to collaborate if they perceive a risk of receiving disproportionately smaller benefits compared to others. As a result, it is crucial to develop new privacy 
preserving and fairness aware optimization and learning paradigms to leverage the power of distributed computing and storage.</p>


<p style='text-align: justify;'>
The topics of this workshop include but are not limited to the following topics:
</p>
<p style='text-align: justify;'>
    • Privacy-preserving Bayesian optimization and distributed optimization <br>
   • Privacy-preserving evolutionary algorithm <br>
• Secure federated data-driven optimization <br>
• Fairness-aware Bayesian optimization and data-driven optimization <br>

• Fairness-aware federated optimization <br>
• Fairness-aware multi-objective machine learning and optimization <br>
• Client selection in large scale cross-device FL <br>
• Data valuation for FL <br>
• Federated machine unlearning and transfer learning <br>
• Malicious attacks and defense in FL <br>
• Optimization strategies in large scale FL <br>
• Privacy-preserving techniques in FL <br>
• Scalability and reliability of FL systems <br>
• Algorithms for training and finetuning large language models in FL <br>
• Algorithms for training foundation models in FL <br>
    </p>


# <span style="display:block;text-align:center">Paper Submission</span>

<p style='text-align: justify;'>
The workshop plans to call for paper submissions and expects around 25 posters with 5 oral presentations among them. The tentative program outline includes interleaved invited speaker sessions and oral presentations, with poster sessions scheduled in the middle of the program. The submission procedure, deadlines, and paper format follow the same guidelines as the IEEE CAI'2025 main conference. Submissions must be made via the IEEE CAI'2025 online system. </p>
<p style='text-align: justify;'><b> Submission Format</b>: Submissions papers (.pdf format) must use the IEEE CAI Article author instructions. The workshop considers two types of submissions: (1) full papers [6 pages]; (2) short papers [2 pages], including figures, tables and references.  </p>
<p style='text-align: justify;'> <b>Submission Due </b>:  15 January, 2025 AoE  </p>
